{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a789e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3: Please read the following webpage on SVM\n",
    "[url]https://www.quarkml.com/2022/10/implementing-SVM-from-scratch-in-python.html\n",
    "Please implement the code and write a one-page summary. Note that the treatment here is on the primal problem. \n",
    "You can refer to Chapter 10 of the book on the traditional treatment of the dual problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77dc422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp311-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/nanoGPT/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading markupsafe-3.0.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Downloading torch-2.9.1-cp311-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:00:45\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [torch]32m7/8\u001b[0m [torch]]x]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 sympy-1.14.0 torch-2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f019bf",
   "metadata": {},
   "source": [
    "## Implementing SVM from scratch in Python\n",
    "\n",
    "### Writing the SVM class\n",
    "\n",
    "\n",
    "### Hindge loss\n",
    "$$f(x) = max{0,1-t} $$\n",
    "\n",
    "$$\\underbrace{min\\frac{1}{2}||w||^2}_{regularizer}+ \\underbrace{C_i\\sum_{i=1}^{n}max\\{0,1-y_n(w^Tx+b)\\}}_{error\\ term}$$\n",
    "where,\n",
    "- w(wights)\n",
    "- b(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfb670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class SVM:\n",
    "\n",
    "    def __init__(self, C = 1.0):\n",
    "        # C = error term\n",
    "        self.C = C\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "\n",
    "    # Hinge Loss Function / Calculation\n",
    "    def hingeloss(self, w, b, x, y):\n",
    "        # Regularizer term\n",
    "        reg = 0.5 * (w * w)\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            # Optimization term\n",
    "            opt_term = y[i] * ((np.dot(w, x[i])) + b)\n",
    "\n",
    "            # calculating loss\n",
    "            loss = reg + self.C * max(0, 1-opt_term)\n",
    "        return nn.MSELOSS([0][0])\n",
    "\n",
    "    def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):\n",
    "        # The number of features in X\n",
    "        number_of_features = X.shape[1]\n",
    "\n",
    "        # The number of Samples in X\n",
    "        number_of_samples = X.shape[0]\n",
    "\n",
    "        c = self.C\n",
    "\n",
    "        # Creating ids from 0 to number_of_samples - 1\n",
    "        ids = np.arange(number_of_samples)\n",
    "\n",
    "        # Shuffling the samples randomly\n",
    "        np.random.shuffle(ids)\n",
    "\n",
    "        # creating an array of zeros\n",
    "        w = np.zeros((1, number_of_features))\n",
    "        b = 0\n",
    "        losses = []\n",
    "\n",
    "        # Gradient Descent logic\n",
    "        for i in range(epochs):\n",
    "            # Calculating the Hinge Loss\n",
    "            l = self.hingeloss(w, b, X, Y)\n",
    "\n",
    "            # Appending all losses \n",
    "            losses.append(l)\n",
    "            \n",
    "            # Starting from 0 to the number of samples with batch_size as interval\n",
    "            for batch_initial in range(0, number_of_samples, batch_size):\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "\n",
    "                for j in range(batch_initial, batch_initial+ batch_size):\n",
    "                    if j < number_of_samples:\n",
    "                        x = ids[j]\n",
    "                        ti = Y[x] * (np.dot(w, X[x].T) + b)\n",
    "\n",
    "                        if ti > 1:\n",
    "                            gradw += 0\n",
    "                            gradb += 0\n",
    "                        else:\n",
    "                            # Calculating the gradients\n",
    "\n",
    "                            #w.r.t w \n",
    "                            gradw += c * Y[x] * X[x]\n",
    "                            # w.r.t b\n",
    "                            gradb += c * Y[x]\n",
    "\n",
    "                # Updating weights and bias\n",
    "                w = w - learning_rate * w + learning_rate * gradw\n",
    "                b = b + learning_rate * gradb\n",
    "        \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "        return self.w, self.b, losses\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        prediction = np.dot(X, self.w[0]) + self.b # w.x + b\n",
    "        return np.sign(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ce0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction.py\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating dataset\n",
    "X, y = datasets.make_blobs(\n",
    "\n",
    "        n_samples = 100, # Number of samples\n",
    "        n_features = 2, # Features\n",
    "        centers = 2,\n",
    "        cluster_std = 1,\n",
    "        random_state=40\n",
    "    )\n",
    "\n",
    "# Classes 1 and -1\n",
    "y = np.where(y == 0, -1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b7938c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2892f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.svm' has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m prediction = \u001b[43msvm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m(X_test)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Loss value\u001b[39;00m\n\u001b[32m      4\u001b[39m lss = losses.pop()\n",
      "\u001b[31mAttributeError\u001b[39m: module 'sklearn.svm' has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "import .SVM as svm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "# Loss value\n",
    "lss = SVMlosses.pop()\n",
    "\n",
    "print(\"Loss:\", lss)\n",
    "print(\"Prediction:\", prediction)\n",
    "print(\"Accuracy:\", accuracy_score(prediction, y_test))\n",
    "print(\"w, b:\", [w, b])\n",
    "\n",
    "'''\n",
    "\n",
    "Loss: 0.0991126738798482\n",
    "Prediction: [-1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
    "  1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1.\n",
    "  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.]\n",
    "Accuracy: 1.0\n",
    "w, b: [array([[0.44477983, 0.15109913]]), 0.05700000000000004]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
